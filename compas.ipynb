{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507d91e6",
   "metadata": {},
   "source": [
    "# COMPAS Case Study: Fairness of a Machine Learning Model\n",
    "\n",
    "Reconstructed from Farhan Rahman's work at https://towardsdatascience.com/compas-case-study-fairness-of-a-machine-learning-model-f0f804108751\n",
    "\n",
    "The above analysis was based on orginal wotk by ProPublica: \n",
    "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
    "\n",
    "Additional material included is from *The Alignment Problem* by Brian Christian.\n",
    "\n",
    "## The use of evidence in parole decisions\n",
    "\n",
    "*\"Our law punishes people for what they do, not who they are. Dispensing punishment on the basis of an immutable characteristic flatly contravenes this guiding principle\"*, US Supreme Court Chief Justice John Roberts.\n",
    "\n",
    "In 1927, the new chairman of the Parole Board of Illinois, Hinton Clabaugh, commissioned a study on the workings of the parole system in the state. He was particularly interested in whether the right people for parole could be selected - those who would not commit further crime. On reviewing evidence, he concluded that certain characteristics, such as having served less than a year, or coming from a farming background, were associated with a lower probability of re-offending. Meanwhile other characteristics, such as those \"living in the criminal underworld\" were associated with a higher probability of re-offending. He recommended that the Parole Board be given a summary sheet for each man to be paroled which would list key attributes of the person and their association with re-offense rates. By 1951 a *'Manual of Parole Prediction'* had been written for Illinois, outlining the evidence gathered. At the end of the book is a present section on *'Scoring by Machine Methods'*, which considers use of punch-card machines to automate processing of data and outputting individualized prediction of likelihood to re-offend. \n",
    "\n",
    "Update of such methods was, however, slow. By 1970 only two states in the US used predictive modeling in parole decisions.But that was to change with the development, in 1998, of *'Correctional Offender Management Profiling for Alternative Sanctions'*, or *'COMPAS'*.\n",
    "\n",
    "## About COMPAS\n",
    "\n",
    "COMPAS, an acronym for *Correctional Offender Management Profiling for Alternative Sanctions*, is an assistive software and support tool used to predict recidivism risk, that is the risk that a criminal defendant will re-offend.  \n",
    "\n",
    "* COMPAS is helpful in ways that it provides scores from 1 (being lowest risk) to 10 (being highest risk).\n",
    "\n",
    "* It also provides a category based evaluation labeled as high risk of recidivism, medium risk of recidivism, or low risk of recidivism. For simplifying things we can convert this multi-class classification problem into binary classification combining the medium risk and high risk of recidivism vs. low risk of recidivism.\n",
    "\n",
    "* The input used for prediction of recidivism is wide-scale and uses 137 factors including age, gender, and criminal history of the defendant as the input. COMPAS **does not** use race as an input.\n",
    "\n",
    "* Race is not an explicit feature considered by the model.\n",
    "\n",
    "## Use of COMPAS, and the bias uncovered by ProPublica\n",
    "\n",
    "COMPAS has been used by the U.S. states of New York, Wisconsin, California, Florida’s Broward County, and other jurisdictions. Depending on the scores generated by this software, the judge can decide upon whether to detain the defendant prior to trial and/or when sentencing. It has been observed that the Defendants who are classified medium or high risk (scores of 5–10), are more likely to be held in prison while awaiting trial than those classified as low risk (scores of 1–4). Although this software might seem to be assistive and helpful but it suffers from machine bias. According to an investigative journal ProPublica:\n",
    "\n",
    "* Though the accuracy is similar for white and black people, the prediction fails differently for the black defendants:\n",
    "\n",
    "|                                           | White | African-American |\n",
    "|-------------------------------------------|-------|------------------|\n",
    "| Labelled high risk, but did not re-offend | 24%   | 45%              |\n",
    "| Labelled lower risk, but did re-offend    | 48%   | 28%              |\n",
    "\n",
    "* Overall, COMPAS correctly predicts recidivism 61 percent of the time. But black people are almost twice as likely as white people to be labeled a higher risk but not actually re-offend. It makes the opposite mistake among white people: They are much more likely than black people to be labeled lower risk but go on to commit other crimes. This a major risk of machine learning models might possess and when it comes to someone’s freedom it’s a flaw that shouldn’t go unnoticed.\n",
    "\n",
    "To get what ProPublica claimed let’s try to make our own model which replicates their analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406210b4",
   "metadata": {},
   "source": [
    "## Formulating ProPublica analysis\n",
    "\n",
    "Before starting any analysis, we need to have the proper tools for that — importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b261cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3093ba",
   "metadata": {},
   "source": [
    "### Read in the data\n",
    "\n",
    "After importing the libraries we need to import the data and to know how the data looks like use the following code to visualize it.\n",
    "\n",
    "Data may be read from local file, or from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969744a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_local = False\n",
    "\n",
    "if read_local:\n",
    "    df = pd.read_csv('compas_data.csv')\n",
    "\n",
    "else:\n",
    "    url = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'\n",
    "    df = pd.read_csv(url)\n",
    "    df.to_csv('compas_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48974f9",
   "metadata": {},
   "source": [
    "As stated earlier to make this into a binary classification problem we carry out the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c36382",
   "metadata": {},
   "source": [
    "### Transform into a binary classification problem\n",
    "\n",
    "First, let’s make this a binary classification problem. We will add a new column that translates the risk score (decile_score) into a binary label.\n",
    "Any score 5 or higher (Medium or High risk) means that a defendant is treated as a likely recividist, and a score of 4 or lower (Low risk) means that a defendant is treated as unlikely to re-offend. As we know that creating a new feature with the help of the existing one might help us to envision data that might go unexplored. The code to do the same is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into a binary classification problem\n",
    "# create feature is_med_or_high_risk\n",
    "df['is_med_or_high_risk']  = (df['decile_score']>=5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300277be",
   "metadata": {},
   "source": [
    "### Evaluate model performance\n",
    "To evaluate the performance of the model, we will compare the model’s predictions to the “truth”:\n",
    "\n",
    "* The risk score prediction of the COMPAS system is in the `decile_score` column,\n",
    "\n",
    "* The classification of COMPAS as medium/high risk or low risk is in the `is_med_or_high_risk` column\n",
    "\n",
    "* The “true” recidivism value (whether or not the defendant committed another crime in the next two years) is in the `two_year_recid` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728d8c3",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Let’s start by computing the accuracy, and the overall recidivism rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification accuracy\n",
    "accuracy = np.mean(df['is_med_or_high_risk']==df['two_year_recid'])\n",
    "print (f'Accuracy: {accuracy:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3070a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two year recidivism rate\n",
    "recidivism = np.mean(df['two_year_recid'])\n",
    "print (f'Recidivism: {recidivism:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179fbafa",
   "metadata": {},
   "source": [
    "This, itself, might already be considered problematic…\n",
    "\n",
    "The accuracy score includes both kinds of errors:\n",
    "\n",
    "* false positives (defendant is predicted as medium/high risk but does not re-offend)\n",
    "\n",
    "* false negatives (defendant is predicted as low risk, but does re-offend)\n",
    "\n",
    "but these errors have different costs. It can be useful to pull them out separately, to see the rate of different types of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73504c4",
   "metadata": {},
   "source": [
    "## Confusion matrices, false positives, and false negatives\n",
    "\n",
    "If we create a confusion matrix, we can use it to derive a whole set of classifier metrics:\n",
    "\n",
    "* True Positive Rate (TPR) also called recall or sensitivity\n",
    "* True Negative Rate (TNR) also called specificity\n",
    "* Positive Predictive Value (PPV) also called precision\n",
    "* Negative Predictive Value (NPV)\n",
    "* False Positive Rate (FPR)\n",
    "* False Discovery Rate (FDR)\n",
    "* False Negative Rate (FNR)\n",
    "* False Omission Rate (FOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e047731",
   "metadata": {},
   "source": [
    "Lets plot a confusion matrix of predicted vs. actual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3204e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.crosstab(df['is_med_or_high_risk'], df['two_year_recid'], \n",
    "                               rownames=['Predicted'], colnames=['Actual'])\n",
    "p = plt.figure(figsize=(5,5));\n",
    "p = sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c401f",
   "metadata": {},
   "source": [
    "We can also use `sklearn`'s `confusion_matrix` to pull out these values and compute any metrics of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[tn , fp],[fn , tp]]  = confusion_matrix(df['two_year_recid'], df['is_med_or_high_risk'])\n",
    "print(\"True negatives:  \", tn)\n",
    "print(\"False positives: \", fp)\n",
    "print(\"False negatives: \", fn)\n",
    "print(\"True positives:  \", tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5222e88",
   "metadata": {},
   "source": [
    "We can replot our confusion matrices, normalising by row or column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b645d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normlaise by row\n",
    "cm = pd.crosstab(df['is_med_or_high_risk'], df['two_year_recid'], \n",
    "                               rownames=['Predicted'], colnames=['Actual'], normalize='index')\n",
    "p = plt.figure(figsize=(5,5));\n",
    "p = sns.heatmap(cm, annot=True, fmt=\".2f\", cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825edcf",
   "metadata": {},
   "source": [
    "When we normalise by row we can more readily see what happened to our 'predicted' groups. We can see that for those predicted not to re-offend, 69% did not re-offend, and 31% did. For those predicted to re-offend, 61% did re-offend, and 39% did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c3c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise by column\n",
    "cm = pd.crosstab(df['is_med_or_high_risk'], df['two_year_recid'], \n",
    "                               rownames=['Predicted'], colnames=['Actual'], normalize='columns')\n",
    "p = plt.figure(figsize=(5,5));\n",
    "p = sns.heatmap(cm, annot=True, fmt=\".2f\", cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e71b0b",
   "metadata": {},
   "source": [
    "When we normalise by column we can more readily see what predictions were made for the groups that did or did not re-offend. We can see that of those that did not re-offend, 68% were predicted not to re-offend, whereas 32% were predicted to offend. Of those who went on to re-offend, 63% were predicted to re-offend, whereas 37% were predicted not to re-offend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911330a0",
   "metadata": {},
   "source": [
    "If we show false positive rate and false negative rate, we see that a defendant has a similar likelihood of being wrongly labeled a likely recidivist and of being wrongly labeled as unlikely to re-offend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729804e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = fp/(fp+tn)\n",
    "fnr  = fn/(fn+tp)\n",
    "\n",
    "print(f'False positive rate (overall): {fpr:0.3f}')\n",
    "print(f'False negative rate (overall): {fnr:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de5bbd",
   "metadata": {},
   "source": [
    "### Analyse risk score\n",
    "\n",
    "We can also directly evaluate the risk score, instead of just the labels. The risk score is meant to indicate the probability that a defendant will re-offend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.groupby('decile_score').agg({'two_year_recid': 'mean'})\n",
    "# plot\n",
    "sns.lineplot(data=d);\n",
    "plt.ylim(0,1);\n",
    "plt.ylabel('Recidivism rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4bde7",
   "metadata": {},
   "source": [
    "Defendants with a higher COMPAS score indeed had higher rates of recidivism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92259fc0",
   "metadata": {},
   "source": [
    "### Receiver-Operator Characteristic curve\n",
    "\n",
    "We can plot a receiver-operator characteristic curve, and calculate area under curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(df['two_year_recid'], df['decile_score'])\n",
    "sns.scatterplot(x=fpr, y=tpr, );\n",
    "sns.lineplot(x=fpr, y=tpr);\n",
    "plt.ylabel(\"TPR\");\n",
    "plt.xlabel(\"FPR\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(df['two_year_recid'], df['decile_score'])\n",
    "print (f'ROC AUC: {auc:0.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47fa6b",
   "metadata": {},
   "source": [
    "## Fairness\n",
    "\n",
    "COMPAS has been under scrutiny for issues related for fairness with respect to race of the defendant.\n",
    "\n",
    "Race is not an explicit input to COMPAS, but some of the questions that are used as input may have strong correlations with race. When we use inputs that correlate with race, race becomes a *redundant variable* - removing it will change little.\n",
    "\n",
    "First, we will find out how frequently each race is represented in the data (this is recorded, but not used in the COMPAS algorithm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6fb4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b343a",
   "metadata": {},
   "source": [
    "We will focus specifically on African-American or Caucasian defendants, since they are the subject of the ProPublica claim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054a1fb",
   "metadata": {},
   "source": [
    "### Accuracy by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict data to black and white pwoplw\n",
    "df = df[df.race.isin([\"African-American\",\"Caucasian\"])]\n",
    "# compare accuracy\n",
    "results = (df['two_year_recid']==df['is_med_or_high_risk']).astype(int).groupby(\n",
    "    df['race']).mean()\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a51101e",
   "metadata": {},
   "source": [
    "It isn’t exactly the same, but it’s similar — within a few points. This is a type of fairness known as **overall accuracy equality**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2be94",
   "metadata": {},
   "source": [
    "### Confusion matrices, and false positives/negatives by race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d15be03",
   "metadata": {},
   "source": [
    "Calculate for black people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd569122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black\n",
    "mask = df['race']=='African-American'\n",
    "df_masked = df[mask]\n",
    "\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(\n",
    "    df_masked['two_year_recid'], df_masked['is_med_or_high_risk'])\n",
    "\n",
    "false_pos_as_frac_of_all = fp / (fp + tp + fn + tn)\n",
    "false_neg_as_frac_of_all = fn / (fp + tp + fn + tn)\n",
    "prop_errors_false_positive = fp / (fp + fn)\n",
    "prop_no_crime_identified_as_high_risk = fp / (fp + tn)\n",
    "prop_crime_identified_as_low_risk = fn / (fn + tp)\n",
    "\n",
    "print(\"True negatives:  \", tn)\n",
    "print(\"False positives: \", fp)\n",
    "print(\"False negatives: \", fn)\n",
    "print(\"True positives:  \", tp)\n",
    "print(f\"False positives as fraction of all: {false_pos_as_frac_of_all:0.3f}\")\n",
    "print(f\"False negatives as fraction of all: {false_neg_as_frac_of_all:0.3f}\")\n",
    "print(f\"Proportion of errors that are false positive: {prop_errors_false_positive:0.3f}\")\n",
    "print(f\"Proportion of non-offenders who were identified as high risk: {prop_no_crime_identified_as_high_risk:0.3f}\")\n",
    "print(f\"Proportion of offenders who were identified as low risk: {prop_crime_identified_as_low_risk:0.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7901e0",
   "metadata": {},
   "source": [
    "Calculate for white people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# White\n",
    "mask = df['race']=='Caucasian'\n",
    "df_masked = df[mask]\n",
    "\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(\n",
    "    df_masked['two_year_recid'], df_masked['is_med_or_high_risk'])\n",
    "\n",
    "false_pos_as_frac_of_all = fp / (fp + tp + fn + tn)\n",
    "false_neg_as_frac_of_all = fn / (fp + tp + fn + tn)\n",
    "prop_errors_false_positive = fp / (fp + fn)\n",
    "prop_no_crime_identified_as_high_risk = fp / (fp + tn)\n",
    "prop_crime_identified_as_low_risk = fn / (fn + tp)\n",
    "\n",
    "print(\"True negatives:  \", tn)\n",
    "print(\"False positives: \", fp)\n",
    "print(\"False negatives: \", fn)\n",
    "print(\"True positives:  \", tp)\n",
    "print(f\"False positives as fraction of all: {false_pos_as_frac_of_all:0.3f}\")\n",
    "print(f\"False negatives as fraction of all: {false_neg_as_frac_of_all:0.3f}\")\n",
    "print(f\"Proportion of errors that are false positive: {prop_errors_false_positive:0.3f}\")\n",
    "print(f\"Proportion of non-offenders who were identified as high risk: {prop_no_crime_identified_as_high_risk:0.3f}\")\n",
    "print(f\"Proportion of offenders who were identified as low risk: {prop_crime_identified_as_low_risk:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd12fe",
   "metadata": {},
   "source": [
    "Here we see a clear disparity by race:\n",
    "\n",
    "* 45% of black people who did not go on to re-offend were classed as high risk of offending, whereas the same figure for white people was 24%.\n",
    "\n",
    "* 48% of white people who went on to re-offend were classed as low risk, whereas the same figure for black people was 28%\n",
    "\n",
    "* 22% of all black people are incorrectly assessed as high risk, compared to 14% of white people.\n",
    "\n",
    "* 19% of white people are incorrectly assessed as low risk, compared to 14% of black people.\n",
    "\n",
    "* For black people, the algorithm incorrectly classifies more people as high risk than low risk. 60% of errors are false positives.\n",
    "\n",
    "* For white people, the algorithm incorrectly classifies more people as low risk than high risk. 43% of errors are false positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b706849",
   "metadata": {},
   "source": [
    "### Positive predictive value by race\n",
    "\n",
    "Next, let’s see whether a defendant who is classified as medium/high risk has the same probability of recidivism for the two groups.\n",
    "\n",
    "In other words, we will compute the PPV for each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute PPV\n",
    "results = df[df['is_med_or_high_risk']==1]['two_year_recid'].groupby(\n",
    "    df['race']).mean()\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77b442",
   "metadata": {},
   "source": [
    "Again, similar (within a few points). This is a type of fairness known as **predictive parity**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f4658",
   "metadata": {},
   "source": [
    "### Assessment of risk score by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration plot\n",
    "d = pd.DataFrame(\n",
    "    df.groupby(['decile_score','race']).agg({'two_year_recid': 'mean'}))\n",
    "d = d.reset_index()\n",
    "im = sns.lineplot(\n",
    "    data=d, x='decile_score', y='two_year_recid', hue='race');\n",
    "im.set(ylim=(0,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d1e46",
   "metadata": {},
   "source": [
    "We can see that for both African-American and Caucasian defendants, for any given COMPAS score, recidivism rates are similar. This is a type of fairness known as **calibration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca5f0e",
   "metadata": {},
   "source": [
    "### Frequency of risk score by race\n",
    "\n",
    "Next, we will look at the frequency with which defendants of each race are assigned each COMPAS score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388fa70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency plot\n",
    "g = sns.FacetGrid(df, col=\"race\", margin_titles=True);\n",
    "g.map(plt.hist, \"decile_score\", bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d604b6",
   "metadata": {},
   "source": [
    "We observe that Caucasian defendants in this sample are more likely to be assigned a low risk score.\n",
    "\n",
    "However, to evaluate whether this is *unfair*, we need to know the true prevalence — whether the rates of recidivism are the same in both populations, according to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf0549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base rates\n",
    "results = df.groupby('race').agg({'two_year_recid': 'mean',  \n",
    "                        'is_med_or_high_risk': 'mean', \n",
    "                        'decile_score': 'mean'})\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be0b63",
   "metadata": {},
   "source": [
    "The predictions of the model are pretty close to the actual prevalence in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe257b7c",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "So far, our analysis suggests that COMPAS is fair with respect to race:\n",
    "\n",
    "* The overall accuracy of the COMPAS label is the same, regardless of race (**overall accuracy equality**)\n",
    "\n",
    "* The likelihood of recidivism among defendants labeled as medium or high risk is similar, regardless of race (**predictive parity**)\n",
    "\n",
    "* For any given COMPAS score, the risk of recidivism is similar, regardless of race — the “meaning” of the score is consistent across race (**calibration**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b544b12e",
   "metadata": {},
   "source": [
    "Because the error types differ between black and white people (an error in a white person is more likely to be a false negative, whereas the error in a black person is more likely to be a false positive, we do not have **statistical parity**. However, but we can’t necessarily expect the dominant error type to be the same when the prevalence of actual positive is different between groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f1bd4",
   "metadata": {},
   "source": [
    "Why is it so tricky to satisfy multiple types of fairness at once? This is due to a proven *impossibility result*.\n",
    "\n",
    "Any time:\n",
    "\n",
    "* the *base rate* (prevalence of the positive condition) is different in the two groups, and\n",
    "\n",
    "* we do not have a perfect classifier\n",
    "\n",
    "Then we cannot simultaneously satisfy:\n",
    "\n",
    "* Equal PPV and NPV for both groups (known as **conditional use accuracy equality**), and\n",
    "\n",
    "* Equal FPR and FNR for both groups (known as **equalized odds** or **conditional procedure accuracy equality**)\n",
    "\n",
    "\n",
    "## What we learned\n",
    "\n",
    "* A model can be biased with respect to age, race, gender, if those features are not used as input to the model (due to correlations with features that are included in the model).\n",
    "\n",
    "* There are many measures of fairness, it may be impossible to satisfy some combination of these simultaneously.\n",
    "\n",
    "* Human biases and unfairness in society leak into the data used to train machine learning models.\n",
    "\n",
    "## References\n",
    "\n",
    "Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, May 2016, Machine Bias\n",
    "\n",
    "Jeff Larson, Surya Mattu, Lauren Kirchner and Julia Angwin, May 2016, How We Analyzed the \n",
    "COMPAS Recidivism Algorithm\n",
    "\n",
    "William Dieterich, Christina Mendoza, and Tim Brennan, July 2016, COMPAS Risk Scales: \n",
    "Demonstrating Accuracy Equity and Predictive Parity\n",
    "\n",
    "Google’s People + AI + Research (PAIR) group explainer: Measuring fairness\n",
    "\n",
    "Another Google Explainer: Attacking discrimination with smarter machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a876e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
